{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/emilynaftalin/Data_Science/General Assembly/dsi/projects/project_3/practice_code'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoic_zen = pd.read_csv('../datasets/practice_datasets/clean_stoic_zen_tokenized.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>merged</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>you need to fight your mind every time it trie...</td>\n",
       "      <td>['you', 'need', 'to', 'fight', 'your', 'mind',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>a phone call creates stronger bonds than text ...</td>\n",
       "      <td>['a', 'phone', 'call', 'creates', 'stronger', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>everything in your life every experience, ever...</td>\n",
       "      <td>['everything', 'in', 'your', 'life', 'every', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the parable of the mexican fisherman got me re...</td>\n",
       "      <td>['the', 'parable', 'of', 'the', 'mexican', 'fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>the key to success and productivity isn t to t...</td>\n",
       "      <td>['the', 'key', 'to', 'success', 'and', 'produc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             merged  \\\n",
       "0      0  you need to fight your mind every time it trie...   \n",
       "1      0  a phone call creates stronger bonds than text ...   \n",
       "2      0  everything in your life every experience, ever...   \n",
       "3      0  the parable of the mexican fisherman got me re...   \n",
       "4      0  the key to success and productivity isn t to t...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['you', 'need', 'to', 'fight', 'your', 'mind',...  \n",
       "1  ['a', 'phone', 'call', 'creates', 'stronger', ...  \n",
       "2  ['everything', 'in', 'your', 'life', 'every', ...  \n",
       "3  ['the', 'parable', 'of', 'the', 'mexican', 'fi...  \n",
       "4  ['the', 'key', 'to', 'success', 'and', 'produc...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoic_zen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>merged</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>1</td>\n",
       "      <td>stoicism and self improvement i have just rece...</td>\n",
       "      <td>['stoicism', 'and', 'self', 'improvement', 'i'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>1</td>\n",
       "      <td>should i go cold turkey on entertainment to pr...</td>\n",
       "      <td>['should', 'i', 'go', 'cold', 'turkey', 'on', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>1</td>\n",
       "      <td>free law of attraction, the secret pdf and boo...</td>\n",
       "      <td>['free', 'law', 'of', 'attraction', 'the', 'se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>1</td>\n",
       "      <td>anxiety i have trouble rationalising with my a...</td>\n",
       "      <td>['anxiety', 'i', 'have', 'trouble', 'rationali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>1</td>\n",
       "      <td>\"some poor, phoneless fool is probably sitting...</td>\n",
       "      <td>['some', 'poor', 'phoneless', 'fool', 'is', 'p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             merged  \\\n",
       "5982      1  stoicism and self improvement i have just rece...   \n",
       "5983      1  should i go cold turkey on entertainment to pr...   \n",
       "5984      1  free law of attraction, the secret pdf and boo...   \n",
       "5985      1  anxiety i have trouble rationalising with my a...   \n",
       "5986      1  \"some poor, phoneless fool is probably sitting...   \n",
       "\n",
       "                                                 tokens  \n",
       "5982  ['stoicism', 'and', 'self', 'improvement', 'i'...  \n",
       "5983  ['should', 'i', 'go', 'cold', 'turkey', 'on', ...  \n",
       "5984  ['free', 'law', 'of', 'attraction', 'the', 'se...  \n",
       "5985  ['anxiety', 'i', 'have', 'trouble', 'rationali...  \n",
       "5986  ['some', 'poor', 'phoneless', 'fool', 'is', 'p...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoic_zen.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB: Making test size 0.25 in instead of 0.33 as it was in the KNN / Decision Tree Notebook_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stoic_zen['merged']\n",
    "y = stoic_zen['label']\n",
    "\n",
    "# splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                   y, \n",
    "                                                   test_size=0.25,\n",
    "                                                   shuffle=True,\n",
    "                                                   stratify=y,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`Random Forest` / `Extra Trees`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Random Forest + CountVectorizer` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming and Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english')\n",
    "\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Will start with a Random Forest Classifier using CountVectorized data and default hyperparameters._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=48)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=48)\n",
    "\n",
    "rf.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8601336302895323"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf, X_train_cvec, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8436722408026756"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf, X_test_cvec, y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (default hyperparameters) score on training set: 0.999554565701559\n",
      "Random Forest (default hyperparameters) score on testing set: 0.8577154308617234\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest (default hyperparameters) score on training set: {rf.score(X_train_cvec, y_train)}')\n",
    "print(f'Random Forest (default hyperparameters) score on testing set: {rf.score(X_test_cvec, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Extra Trees + CountVectorizer` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=48)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(random_state=48)\n",
    "\n",
    "et.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8623608017817371"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(et, X_train_cvec, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8450167224080267"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(et, X_test_cvec, y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees (default hyperparameters) score on training set: 0.999554565701559\n",
      "Extra Tress (default hyperparameters) score on testing set: 0.8643954575818303\n"
     ]
    }
   ],
   "source": [
    "print(f'Extra Trees (default hyperparameters) score on training set: {et.score(X_train_cvec, y_train)}')\n",
    "print(f'Extra Tress (default hyperparameters) score on testing set: {et.score(X_test_cvec, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Random + CountVectorizer Pipe` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Both Random Forest and Extra Trees Classifiers are **severely** overfit; next will move to a Pipeline and will tune a few hyperparameters._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('rf', RandomForestClassifier(max_features=0.6, max_depth=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8189342142395307"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, X_train, y_train, cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('rf', RandomForestClassifier(max_depth=5, max_features=0.6))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8356347438752784"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156312625250501"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " word_importances = [(el, index_to_word[i]) for i, el in enumerate(np.exp(estimator.coef_[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting feature importances from \n",
    "\n",
    "imp = pd.DataFrame(pipe.named_steps['rf'].feature_importances_, index=pipe.named_steps['cvec'].get_feature_names(), columns=['feature_importances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stoic</th>\n",
       "      <td>0.365838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoicism</th>\n",
       "      <td>0.359994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>0.062956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marcus</th>\n",
       "      <td>0.061247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>removed</th>\n",
       "      <td>0.032321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frustrated</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruits world</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruits life</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fruits influence</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zuckerberg said</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127595 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  feature_importances\n",
       "stoic                        0.365838\n",
       "stoicism                     0.359994\n",
       "just                         0.062956\n",
       "marcus                       0.061247\n",
       "removed                      0.032321\n",
       "...                               ...\n",
       "frustrated                   0.000000\n",
       "fruits world                 0.000000\n",
       "fruits life                  0.000000\n",
       "fruits influence             0.000000\n",
       "zuckerberg said              0.000000\n",
       "\n",
       "[127595 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.sort_values(by='feature_importances', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3658376886206641,\n",
       " 0.35999412939894526,\n",
       " 0.06295637702783738,\n",
       " 0.061246860006997035,\n",
       " 0.032320846070885687,\n",
       " 0.021257454222431877,\n",
       " 0.014466131966752643,\n",
       " 0.010223729519460935,\n",
       " 0.00691964694709074,\n",
       " 0.005927479658266051,\n",
       " 0.005600126357929635,\n",
       " 0.0026383408317187337,\n",
       " 0.002290195026821617,\n",
       " 0.002230406319609703,\n",
       " 0.0019434861049228115,\n",
       " 0.0018258719749997833,\n",
       " 0.0014441152612138365,\n",
       " 0.0013494991518284685,\n",
       " 0.0012968206657579418,\n",
       " 0.0011584712867176296]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(imp, reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " word_importances = [(el, index_to_word[i]) for i, el in enumerate(np.exp(estimator.coef_[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ascending' is an invalid keyword argument for sort()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ae11497908f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'ascending' is an invalid keyword argument for sort()"
     ]
    }
   ],
   "source": [
    "imp.sort(=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sort' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-7895eb2f3673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sort' is not defined"
     ]
    }
   ],
   "source": [
    "sort(imp, ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.0\n",
      "Feature: 1, Score: 0.0\n",
      "Feature: 2, Score: 0.0\n",
      "Feature: 3, Score: 0.0\n",
      "Feature: 4, Score: 0.0\n",
      "Feature: 5, Score: 0.0\n",
      "Feature: 6, Score: 0.0\n",
      "Feature: 7, Score: 0.0\n",
      "Feature: 8, Score: 0.0\n",
      "Feature: 9, Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(imp):\n",
    "    print(f'Feature: {i}, Score: {100_000_000*v}')\n",
    "#     print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Less overfit!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Extra Trees + CountVectorizer Pipeline` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_et = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('et', ExtraTreesClassifier(max_features=0.6, max_depth=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('et', ExtraTreesClassifier(max_depth=5, max_features=0.6))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856792873051225"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_et.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe_et' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b041cf83931a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe_et\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe_et' is not defined"
     ]
    }
   ],
   "source": [
    "pipe_et.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Extra Trees + TfidfVectorizer Pipeline` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
       "                ('et', ExtraTreesClassifier(max_depth=5, max_features=0.6))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_et_tf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('et', ExtraTreesClassifier(max_features=0.6, max_depth=5))\n",
    "])\n",
    "\n",
    "pipe_et_tf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.834966592427617"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_et_tf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8176352705410822"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_et_tf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Extra Trees has better accuracy than the Random Forest Pipeline but is still overfit._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Extra Trees + CountVectorizer Pipeline --> Gridsearch` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_To save time, will start with a gridsearch using Extra Trees since the accuracy was higher on the above pipeline._\n",
    "\n",
    "_I will countvectorizer as my transformer because this had higher accuracy than tfidf._\n",
    "\n",
    "_Hyperparameters are also informed by the best parameters found in the Decision Tree grid search in another notebook._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building cvec pipeline in two stages \n",
    "pipe_rf_cvec = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('et', ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "# hyperparamters for transformer and estimator \n",
    "pipe_params_rf_cvec = {\n",
    "    'cvec__max_features':[2000, 3000, 4000],\n",
    "    'cvec__ngram_range': [(1,2),(1,3)],\n",
    "    'cvec__min_df': [0.75, 1],\n",
    "    'et__ccp_alpha': [0.001, 0.1, 0, 1],\n",
    "    'et__max_depth': [4,6,8],\n",
    "    'et__min_samples_leaf': [4,6,8],\n",
    "    'et__min_samples_split': [5,10]\n",
    "}\n",
    "\n",
    "# gridsearch instantiation \n",
    "grid_rf_cvec = GridSearchCV(pipe_rf_cvec,\n",
    "                            pipe_params_rf_cvec,\n",
    "                            cv = 5,\n",
    "                            verbose = 2, \n",
    "                            n_jobs = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'dt__ccp_alpha': 0.001,\n",
    "#  'dt__max_depth': 8,\n",
    "#  'dt__min_samples_leaf': 6,\n",
    "#  'dt__min_samples_split': 5,\n",
    "#  'tfidf__max_features': 3000,\n",
    "#  'tfidf__min_df': 1,\n",
    "#  'tfidf__ngram_range': (1, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilynaftalin/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.75723831 0.76146993 0.76057906 0.75434298 0.7596882  0.7623608\n",
      " 0.77282851 0.77037862 0.77193764 0.77238307 0.76859688 0.76837416\n",
      " 0.78062361 0.77973274 0.78062361 0.78040089 0.77951002 0.77995546\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.75567929 0.76013363 0.75679287 0.75902004 0.75389755 0.76347439\n",
      " 0.7714922  0.77394209 0.77126949 0.77193764 0.77216036 0.76971047\n",
      " 0.78173719 0.78396437 0.78062361 0.77327394 0.77639198 0.78017817\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.76124722 0.76325167 0.76169265 0.75991091 0.75991091 0.76146993\n",
      " 0.7714922  0.76592428 0.76971047 0.76859688 0.77082405 0.77438753\n",
      " 0.77750557 0.78017817 0.77928731 0.77928731 0.78418708 0.78106904\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.7596882  0.76057906 0.75746102 0.75857461 0.75902004 0.75902004\n",
      " 0.77327394 0.76904232 0.77216036 0.77037862 0.76636971 0.77082405\n",
      " 0.7766147  0.77928731 0.77884187 0.77928731 0.77772829 0.77995546\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.76436526 0.75612472 0.75879733 0.75723831 0.7545657  0.75835189\n",
      " 0.76503341 0.7674833  0.76659243 0.76703786 0.76703786 0.76904232\n",
      " 0.77884187 0.7766147  0.77728285 0.78062361 0.77683742 0.77906459\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.75612472 0.75991091 0.7532294  0.75523385 0.75545657 0.75501114\n",
      " 0.76525612 0.76458797 0.7701559  0.76636971 0.77037862 0.76592428\n",
      " 0.77995546 0.77594655 0.77282851 0.77483296 0.7766147  0.77639198\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.75857461 0.75924276 0.75612472 0.75634744 0.7545657  0.7532294\n",
      " 0.76859688 0.76391982 0.76614699 0.76859688 0.76258352 0.7701559\n",
      " 0.77772829 0.77550111 0.77906459 0.7752784  0.77728285 0.77483296\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.75857461 0.75657016 0.75812918 0.74877506 0.76035635 0.75144766\n",
      " 0.76926503 0.76770601 0.76948775 0.77193764 0.7674833  0.76614699\n",
      " 0.77750557 0.77861915 0.77839644 0.77438753 0.77817372 0.77260579\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.75612472 0.75278396 0.75367483 0.74922049 0.75256125 0.75478842\n",
      " 0.76993318 0.76525612 0.76080178 0.76525612 0.76458797 0.76414254\n",
      " 0.77594655 0.7752784  0.77550111 0.77126949 0.77394209 0.77438753\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.75367483 0.75835189 0.75857461 0.7545657  0.75478842 0.7596882\n",
      " 0.76481069 0.76035635 0.76636971 0.76525612 0.76258352 0.76703786\n",
      " 0.7701559  0.77438753 0.77483296 0.77282851 0.77594655 0.77104677\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.75300668 0.75478842 0.75144766 0.75857461 0.75345212 0.75501114\n",
      " 0.77060134 0.76347439 0.76124722 0.76191537 0.76436526 0.76057906\n",
      " 0.77505568 0.77327394 0.7714922  0.77594655 0.77104677 0.77884187\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.75567929 0.75679287 0.74966592 0.75434298 0.7610245  0.7545657\n",
      " 0.76213808 0.76971047 0.76948775 0.76703786 0.76124722 0.7623608\n",
      " 0.77594655 0.77616927 0.77438753 0.77216036 0.7714922  0.777951\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272\n",
      " 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272 0.50022272]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell took 2968.1651360988617 seconds to run\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# gridsearching on training data\n",
    "grid_rf_cvec.fit(X_train, y_train)\n",
    "\n",
    "print(f'This cell took {time.time() - t0} seconds to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7841870824053453"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_cvec.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 3),\n",
       " 'et__ccp_alpha': 0.001,\n",
       " 'et__max_depth': 8,\n",
       " 'et__min_samples_leaf': 8,\n",
       " 'et__min_samples_split': 5}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_cvec.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Tress Gridsearch Training Score: 0.7866369710467706\n",
      "Extra Tress Gridsearch Testing Score: 0.7682030728122913\n"
     ]
    }
   ],
   "source": [
    "print(f'Extra Tress Gridsearch Training Score: {grid_rf_cvec.score(X_train, y_train)}')\n",
    "print(f'Extra Tress Gridsearch Testing Score: {grid_rf_cvec.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_poor accuracy but not too overfit_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
